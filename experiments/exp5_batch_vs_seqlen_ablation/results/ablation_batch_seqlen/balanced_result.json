{
  "config_name": "balanced",
  "batch_size": 26,
  "seq_len": 1024,
  "lr": 0.01,
  "grad_accum": 1,
  "val_loss": 5.866008615493774,
  "val_acc": 0.1921645960211754,
  "throughput": 60653.77439574541,
  "time": 21.947521209716797,
  "peak_memory_gb": 21.895435264,
  "train_history": [
    {
      "step": 0,
      "time": 1.743204116821289,
      "tokens": 26624,
      "loss": 10.808822631835938,
      "acc": 0.014685997739434242
    },
    {
      "step": 1,
      "time": 2.0823566913604736,
      "tokens": 53248,
      "loss": 10.801499366760254,
      "acc": 0.015286959707736969
    },
    {
      "step": 2,
      "time": 2.358323097229004,
      "tokens": 79872,
      "loss": 10.706228256225586,
      "acc": 0.015512320213019848
    },
    {
      "step": 3,
      "time": 2.6324000358581543,
      "tokens": 106496,
      "loss": 10.492375373840332,
      "acc": 0.015512320213019848
    },
    {
      "step": 4,
      "time": 2.9058804512023926,
      "tokens": 133120,
      "loss": 10.222907066345215,
      "acc": 0.017014723271131516
    },
    {
      "step": 5,
      "time": 3.1804869174957275,
      "tokens": 159744,
      "loss": 9.939335823059082,
      "acc": 0.014761118218302727
    },
    {
      "step": 6,
      "time": 3.4567008018493652,
      "tokens": 186368,
      "loss": 9.568929672241211,
      "acc": 0.01675180345773697
    },
    {
      "step": 7,
      "time": 3.732062339782715,
      "tokens": 212992,
      "loss": 9.197693824768066,
      "acc": 0.01724008470773697
    },
    {
      "step": 8,
      "time": 4.007451295852661,
      "tokens": 239616,
      "loss": 8.864755630493164,
      "acc": 0.03079928085207939
    },
    {
      "step": 9,
      "time": 4.286960124969482,
      "tokens": 266240,
      "loss": 8.477952003479004,
      "acc": 0.07245343178510666
    },
    {
      "step": 10,
      "time": 4.562302350997925,
      "tokens": 292864,
      "loss": 8.241171836853027,
      "acc": 0.09311148524284363
    },
    {
      "step": 11,
      "time": 4.837044954299927,
      "tokens": 319488,
      "loss": 7.996404647827148,
      "acc": 0.09408804774284363
    },
    {
      "step": 12,
      "time": 5.11141037940979,
      "tokens": 346112,
      "loss": 7.806041240692139,
      "acc": 0.09239783883094788
    },
    {
      "step": 13,
      "time": 5.385417699813843,
      "tokens": 372736,
      "loss": 7.596494674682617,
      "acc": 0.09254807978868484
    },
    {
      "step": 14,
      "time": 5.659593343734741,
      "tokens": 399360,
      "loss": 7.509340763092041,
      "acc": 0.09972205758094788
    },
    {
      "step": 15,
      "time": 5.9338812828063965,
      "tokens": 425984,
      "loss": 7.2850751876831055,
      "acc": 0.09825721383094788
    },
    {
      "step": 16,
      "time": 6.207151889801025,
      "tokens": 452608,
      "loss": 7.31031608581543,
      "acc": 0.10265174508094788
    },
    {
      "step": 17,
      "time": 6.4812891483306885,
      "tokens": 479232,
      "loss": 7.251086711883545,
      "acc": 0.10494291037321091
    },
    {
      "step": 18,
      "time": 6.759643077850342,
      "tokens": 505856,
      "loss": 7.153506755828857,
      "acc": 0.12131911516189575
    },
    {
      "step": 19,
      "time": 7.034092664718628,
      "tokens": 532480,
      "loss": 7.254191875457764,
      "acc": 0.12417368590831757
    },
    {
      "step": 20,
      "time": 7.308592796325684,
      "tokens": 559104,
      "loss": 7.2065629959106445,
      "acc": 0.13266226649284363
    },
    {
      "step": 21,
      "time": 7.583341121673584,
      "tokens": 585728,
      "loss": 6.992358684539795,
      "acc": 0.1322866678237915
    },
    {
      "step": 22,
      "time": 7.8576319217681885,
      "tokens": 612352,
      "loss": 6.9960503578186035,
      "acc": 0.14453125
    },
    {
      "step": 23,
      "time": 8.132522583007812,
      "tokens": 638976,
      "loss": 6.945254802703857,
      "acc": 0.1426156908273697
    },
    {
      "step": 24,
      "time": 8.40687370300293,
      "tokens": 665600,
      "loss": 6.9765801429748535,
      "acc": 0.14096304774284363
    },
    {
      "step": 25,
      "time": 8.681365966796875,
      "tokens": 692224,
      "loss": 6.898240089416504,
      "acc": 0.14851263165473938
    },
    {
      "step": 26,
      "time": 8.956336975097656,
      "tokens": 718848,
      "loss": 6.855559349060059,
      "acc": 0.15166766941547394
    },
    {
      "step": 27,
      "time": 9.231052875518799,
      "tokens": 745472,
      "loss": 6.799221515655518,
      "acc": 0.14674730598926544
    },
    {
      "step": 28,
      "time": 9.504530191421509,
      "tokens": 772096,
      "loss": 6.7835493087768555,
      "acc": 0.15640024840831757
    },
    {
      "step": 29,
      "time": 9.778973817825317,
      "tokens": 798720,
      "loss": 6.6776604652404785,
      "acc": 0.15760217607021332
    },
    {
      "step": 30,
      "time": 10.053532838821411,
      "tokens": 825344,
      "loss": 6.564758777618408,
      "acc": 0.16105769574642181
    },
    {
      "step": 31,
      "time": 10.327744007110596,
      "tokens": 851968,
      "loss": 6.519195556640625,
      "acc": 0.1645883470773697
    },
    {
      "step": 32,
      "time": 10.602436542510986,
      "tokens": 878592,
      "loss": 6.435519218444824,
      "acc": 0.1684194803237915
    },
    {
      "step": 33,
      "time": 10.88009762763977,
      "tokens": 905216,
      "loss": 6.406396865844727,
      "acc": 0.16845703125
    },
    {
      "step": 34,
      "time": 11.155200719833374,
      "tokens": 931840,
      "loss": 6.399204730987549,
      "acc": 0.1758188158273697
    },
    {
      "step": 35,
      "time": 11.429327726364136,
      "tokens": 958464,
      "loss": 6.391180038452148,
      "acc": 0.17146185040473938
    },
    {
      "step": 36,
      "time": 11.70379114151001,
      "tokens": 985088,
      "loss": 6.232381343841553,
      "acc": 0.17788462340831757
    },
    {
      "step": 37,
      "time": 11.978583335876465,
      "tokens": 1011712,
      "loss": 6.33162784576416,
      "acc": 0.1708608865737915
    },
    {
      "step": 38,
      "time": 12.252650260925293,
      "tokens": 1038336,
      "loss": 6.331015586853027,
      "acc": 0.18175330758094788
    },
    {
      "step": 39,
      "time": 12.526623487472534,
      "tokens": 1064960,
      "loss": 6.230971813201904,
      "acc": 0.17897386848926544
    },
    {
      "step": 40,
      "time": 12.800394535064697,
      "tokens": 1091584,
      "loss": 6.221378803253174,
      "acc": 0.17724609375
    },
    {
      "step": 41,
      "time": 13.074250221252441,
      "tokens": 1118208,
      "loss": 6.302757740020752,
      "acc": 0.17563101649284363
    },
    {
      "step": 42,
      "time": 13.348455429077148,
      "tokens": 1144832,
      "loss": 6.121962547302246,
      "acc": 0.18325571715831757
    },
    {
      "step": 43,
      "time": 13.622163534164429,
      "tokens": 1171456,
      "loss": 6.039080619812012,
      "acc": 0.18543420732021332
    },
    {
      "step": 44,
      "time": 13.895654439926147,
      "tokens": 1198080,
      "loss": 5.993484973907471,
      "acc": 0.1923452615737915
    },
    {
      "step": 45,
      "time": 14.168715953826904,
      "tokens": 1224704,
      "loss": 6.03652286529541,
      "acc": 0.18663612008094788
    },
    {
      "step": 46,
      "time": 14.442793369293213,
      "tokens": 1251328,
      "loss": 6.111044883728027,
      "acc": 0.18242938816547394
    },
    {
      "step": 47,
      "time": 14.716388463973999,
      "tokens": 1277952,
      "loss": 5.976791858673096,
      "acc": 0.18321815133094788
    },
    {
      "step": 48,
      "time": 14.991665601730347,
      "tokens": 1304576,
      "loss": 6.035713195800781,
      "acc": 0.18438251316547394
    },
    {
      "step": 49,
      "time": 15.265223503112793,
      "tokens": 1331200,
      "loss": 5.916691780090332,
      "acc": 0.18528395891189575
    }
  ]
}