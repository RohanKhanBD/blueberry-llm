{
  "final_metrics": {
    "val_loss": 6.8493530657603126,
    "val_accuracy": 0.12065305332162392,
    "val_perplexity": 943.2704752706425
  },
  "total_time_minutes": 0.6911123236020406,
  "stopped_early": false,
  "actual_steps": 200,
  "history": {
    "steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200
    ],
    "val_losses": [
      10.50786197648874,
      9.552564115490593,
      8.86026239226648,
      7.917143953141391,
      7.747828008429321,
      7.7400747609222735,
      7.623360871426208,
      7.565697329625645,
      7.47225949115551,
      7.386926143834954,
      7.322177115261765,
      7.257409722560707,
      7.214075636105487,
      7.148948635734855,
      7.101251295514325,
      7.046553016972626,
      7.01212898160038,
      6.9532708902662295,
      6.908962534510205,
      6.8493530657603126
    ],
    "val_accuracies": [
      0.01640931313229101,
      0.07519379308914137,
      0.08571151971122928,
      0.07749649063362216,
      0.07439165220277569,
      0.08826315753078907,
      0.06083132221861105,
      0.09448666440776417,
      0.08276572645612773,
      0.09985271033724492,
      0.0932627080552924,
      0.10028144081099209,
      0.10335170420363314,
      0.10268786347008914,
      0.1054192914883171,
      0.10628366744345252,
      0.10850338489624031,
      0.11348910540546148,
      0.11759661994426504,
      0.12065305332162392
    ],
    "val_perplexities": [
      36602.13959237033,
      14080.753099902013,
      7046.331404885361,
      2743.9230711055507,
      2316.535450997233,
      2298.6442254609797,
      2045.4250011880522,
      1930.814724026676,
      1758.5756861348557,
      1614.7350134494452,
      1513.4954395286588,
      1418.577265404529,
      1358.41741554459,
      1272.7671096326808,
      1213.4845526652166,
      1148.8916993576643,
      1110.0151930003158,
      1046.5673427465283,
      1001.2079845543669,
      943.2704752706425
    ],
    "elapsed_times": [
      0.0375822385152181,
      0.07283026774724324,
      0.1080456296602885,
      0.14276732603708903,
      0.17723041772842407,
      0.211195170879364,
      0.24563314119974772,
      0.28008463780085247,
      0.31390091180801394,
      0.34771496454874673,
      0.38154897689819334,
      0.4159512440363566,
      0.45030107100804645,
      0.4847208658854167,
      0.5191634813944499,
      0.5541653315226237,
      0.589058518409729,
      0.6239340623219808,
      0.6586749951044718,
      0.6911122322082519
    ],
    "learning_rates": [
      0.0004,
      0.001,
      0.0014,
      0.002,
      0.0019995079316068335,
      0.001996926043706003,
      0.0019939783397182743,
      0.0019877251730624503,
      0.0019823419692873282,
      0.0019724602393453973,
      0.0019646783085231633,
      0.001951235517530571,
      0.0019411080181395148,
      0.0019241959939895518,
      0.0019117921071196632,
      0.0018915263760858401,
      0.0018769308328618166,
      0.0018534498304362756,
      0.0018367623332180235,
      0.0018102264584567542
    ]
  },
  "experiment_config": {
    "name": "adam_lr_0.002_fast",
    "description": "[FAST] Adam LR 0.002 (200 steps)",
    "optimizer_type": "adam",
    "max_steps": 200,
    "lr_schedule_type": "cosine",
    "use_early_stopping": false,
    "load_balancing_weight": 0.01,
    "dropout": 0.1,
    "warmup_steps_ratio": 0.05,
    "min_lr_ratio": 0.1,
    "grad_clip": 1.0,
    "adam_lr": 0.002
  }
}