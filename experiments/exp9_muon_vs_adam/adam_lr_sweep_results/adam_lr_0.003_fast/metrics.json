{
  "final_metrics": {
    "val_loss": 6.998696143551345,
    "val_accuracy": 0.10956829607296716,
    "val_perplexity": 1095.2042379690458
  },
  "total_time_minutes": 0.6811121702194214,
  "stopped_early": false,
  "actual_steps": 200,
  "history": {
    "steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200
    ],
    "val_losses": [
      10.399204847248198,
      9.264005283584865,
      8.492712937479727,
      7.816058947425007,
      7.835858845458014,
      7.68423979526695,
      7.974344068196974,
      7.651236648694366,
      7.5507669465701905,
      7.46710507187321,
      7.425433061148168,
      7.3304397192102435,
      7.281571770725318,
      7.242086386933344,
      7.210834380173431,
      7.175794828906919,
      7.125678493782825,
      7.114099081329238,
      7.055671029714308,
      6.998696143551345
    ],
    "val_accuracies": [
      0.01640931313229101,
      0.073672491408103,
      0.053024278591827845,
      0.08289019659366724,
      0.08777219198827214,
      0.05700040798545082,
      0.08904455339423151,
      0.07969546306348668,
      0.08310456183054082,
      0.07858214683327225,
      0.0813204898591413,
      0.10025378078042776,
      0.0992372746571885,
      0.10080006638407335,
      0.09696915215091313,
      0.0989053542904165,
      0.09830374862564223,
      0.10284690864583405,
      0.10639430756570986,
      0.10956829607296716
    ],
    "val_perplexities": [
      32833.50763795552,
      10551.30980768203,
      4879.08478635881,
      2480.111871022763,
      2529.707204197086,
      2173.816799491002,
      2905.4514689143252,
      2103.244956966632,
      1902.201058616263,
      1749.5345705760917,
      1678.1261469164986,
      1526.0526591488326,
      1453.2704388607885,
      1397.0056266752365,
      1354.0215649251675,
      1307.3988465184748,
      1243.4915822041933,
      1229.1757248585238,
      1159.415212365377,
      1095.2042379690458
    ],
    "elapsed_times": [
      0.037832061449686684,
      0.07313450177510579,
      0.10763285954793295,
      0.1421038269996643,
      0.1753152092297872,
      0.20823347568511963,
      0.24199062983194988,
      0.274658997853597,
      0.3063963413238525,
      0.3388586163520813,
      0.37239240407943724,
      0.4065938115119934,
      0.44046210845311484,
      0.47416794300079346,
      0.5082105755805969,
      0.5435280879338582,
      0.5783246517181396,
      0.6134308775266012,
      0.6485130111376445,
      0.6811120669047038
    ],
    "learning_rates": [
      0.0006000000000000001,
      0.0015,
      0.0021,
      0.003,
      0.0029992618974102503,
      0.002995389065559004,
      0.0029909675095774117,
      0.0029815877595936752,
      0.0029735129539309926,
      0.002958690359018096,
      0.002947017462784745,
      0.002926853276295857,
      0.0029116620272092724,
      0.0028862939909843274,
      0.002867688160679495,
      0.00283728956412876,
      0.002815396249292725,
      0.0027801747456544135,
      0.002755143499827035,
      0.0027153396876851313
    ]
  },
  "experiment_config": {
    "name": "adam_lr_0.003_fast",
    "description": "[FAST] Adam LR 0.003 (200 steps)",
    "optimizer_type": "adam",
    "max_steps": 200,
    "lr_schedule_type": "cosine",
    "use_early_stopping": false,
    "load_balancing_weight": 0.01,
    "dropout": 0.1,
    "warmup_steps_ratio": 0.05,
    "min_lr_ratio": 0.1,
    "grad_clip": 1.0,
    "adam_lr": 0.003
  }
}