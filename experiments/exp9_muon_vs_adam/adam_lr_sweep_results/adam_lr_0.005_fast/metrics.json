{
  "final_metrics": {
    "val_loss": 7.344465196764511,
    "val_accuracy": 0.08994350438757234,
    "val_perplexity": 1547.6070786428743
  },
  "total_time_minutes": 0.646109672387441,
  "stopped_early": false,
  "actual_steps": 200,
  "history": {
    "steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200
    ],
    "val_losses": [
      10.234702740456948,
      8.782048002991154,
      8.107049669056815,
      8.172487801460832,
      8.219313085711045,
      7.8636854613206415,
      7.752008948646249,
      7.817153221305604,
      7.769310354765228,
      7.666396815027028,
      7.6411521746497275,
      7.634822968459382,
      7.630192540980902,
      7.600784274798821,
      7.557713633291292,
      7.524346087088433,
      7.497395791771555,
      7.448282262040532,
      7.410616064240149,
      7.344465196764511
    ],
    "val_accuracies": [
      0.03351704203633145,
      0.07923907255917517,
      0.050362000650010716,
      0.0531280037064441,
      0.06881815604406243,
      0.07477197762303528,
      0.0739698367366696,
      0.06112866754717764,
      0.05590783677815964,
      0.07502091789811428,
      0.07566401360873504,
      0.07515230304329486,
      0.07410122188185018,
      0.07495868282934452,
      0.07461984745493144,
      0.07750340564126323,
      0.08041462385815937,
      0.08510991404645502,
      0.08372691251823833,
      0.08994350438757234
    ],
    "val_perplexities": [
      27853.188871128845,
      6516.208732125392,
      3317.7750416070858,
      3542.1451651787856,
      3711.951713894047,
      2601.088944983813,
      2326.241022296944,
      2482.827278092738,
      2366.838446523153,
      2135.3734214455544,
      2082.141425641709,
      2069.004739492361,
      2059.446509516921,
      1999.7636444805605,
      1915.4610566538288,
      1852.601389947955,
      1803.3400211861792,
      1716.9114070482956,
      1653.4446612876102,
      1547.6070786428743
    ],
    "elapsed_times": [
      0.03794929981231689,
      0.07293119430541992,
      0.10587100982666016,
      0.1372342586517334,
      0.16846834421157836,
      0.19997530778249104,
      0.23142011960347494,
      0.26387770573298136,
      0.29519399801890056,
      0.32607973416646324,
      0.3566326936086019,
      0.3868207136789958,
      0.41767882903416953,
      0.448796820640564,
      0.48062225977579753,
      0.5135448137919109,
      0.5466819087664286,
      0.580598243077596,
      0.6143732190132141,
      0.6461095372835796
    ],
    "learning_rates": [
      0.001,
      0.0025,
      0.0034999999999999996,
      0.005,
      0.004998769829017083,
      0.004992315109265007,
      0.004984945849295686,
      0.004969312932656125,
      0.004955854923218321,
      0.004931150598363494,
      0.004911695771307909,
      0.004878088793826428,
      0.004852770045348787,
      0.00481048998497388,
      0.004779480267799159,
      0.0047288159402146005,
      0.0046923270821545415,
      0.004633624576090689,
      0.004591905833045059,
      0.004525566146141886
    ]
  },
  "experiment_config": {
    "name": "adam_lr_0.005_fast",
    "description": "[FAST] Adam LR 0.005 (200 steps)",
    "optimizer_type": "adam",
    "max_steps": 200,
    "lr_schedule_type": "cosine",
    "use_early_stopping": false,
    "load_balancing_weight": 0.01,
    "dropout": 0.1,
    "warmup_steps_ratio": 0.05,
    "min_lr_ratio": 0.1,
    "grad_clip": 1.0,
    "adam_lr": 0.005
  }
}