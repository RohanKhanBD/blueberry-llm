{
  "final_metrics": {
    "val_loss": 7.422007634867207,
    "val_accuracy": 0.08141729996611646,
    "val_perplexity": 1672.3876834628873
  },
  "total_time_minutes": 0.6441571950912476,
  "stopped_early": false,
  "actual_steps": 200,
  "history": {
    "steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200
    ],
    "val_losses": [
      10.136033061536377,
      8.41616320862787,
      8.625620029840368,
      8.331669069431696,
      8.81352537512358,
      7.930370344290043,
      7.7881539280759995,
      7.700853546600881,
      7.662885290152614,
      7.647557170989235,
      7.614693555730813,
      7.591072485219463,
      7.565143657657367,
      7.541823328173202,
      7.5171390927722515,
      7.498298163127562,
      7.487077131709446,
      7.469861451812852,
      7.450314685228435,
      7.422007634867207
    ],
    "val_accuracies": [
      0.03691231078810342,
      0.07161873413870122,
      0.055340806151590795,
      0.03933947847012371,
      0.053867909524040025,
      0.04810770815901751,
      0.05705572804657949,
      0.06687503889691798,
      0.07703318512166955,
      0.0640260557487916,
      0.07169479922275314,
      0.07218576476527007,
      0.07932896765850926,
      0.07836778159639866,
      0.08199816060796747,
      0.07993057332328352,
      0.07871353197845284,
      0.08192209552391555,
      0.08201890563089072,
      0.08141729996611646
    ],
    "val_perplexities": [
      25236.1573733394,
      4519.529654296698,
      5572.616826348571,
      4153.343989796732,
      6724.58421049919,
      2780.4563399931526,
      2411.8610009974423,
      2210.233724475081,
      2127.8881546019566,
      2095.520334042977,
      2027.7732640638249,
      1980.4363639082908,
      1929.745981931615,
      1885.2643488628685,
      1839.2976996542227,
      1804.9680379938352,
      1784.8276442515219,
      1754.3636048392893,
      1720.4044460679017,
      1672.3876834628873
    ],
    "elapsed_times": [
      0.038281206289927164,
      0.07291914621988932,
      0.10479336977005005,
      0.13635712067286174,
      0.17052691380182902,
      0.20309219360351563,
      0.23286593755086263,
      0.2631920059521993,
      0.2948075731595357,
      0.32693469524383545,
      0.35885698000590005,
      0.3914146383603414,
      0.4236233393351237,
      0.45505183935165405,
      0.48607420523961387,
      0.517605972290039,
      0.5499064008394877,
      0.5822316567103069,
      0.6143398602803548,
      0.6441571036974589
    ],
    "learning_rates": [
      0.0014000000000000002,
      0.0035,
      0.0049,
      0.007,
      0.006998277760623917,
      0.00698924115297101,
      0.006978924189013961,
      0.006957038105718576,
      0.006938196892505649,
      0.006903610837708891,
      0.006876374079831072,
      0.006829324311356999,
      0.006793878063488302,
      0.006734685978963431,
      0.0066912723749188215,
      0.00662034231630044,
      0.006569257915016358,
      0.006487074406526965,
      0.006428668166263082,
      0.00633579260459864
    ]
  },
  "experiment_config": {
    "name": "adam_lr_0.007_fast",
    "description": "[FAST] Adam LR 0.007 (200 steps)",
    "optimizer_type": "adam",
    "max_steps": 200,
    "lr_schedule_type": "cosine",
    "use_early_stopping": false,
    "load_balancing_weight": 0.01,
    "dropout": 0.1,
    "warmup_steps_ratio": 0.05,
    "min_lr_ratio": 0.1,
    "grad_clip": 1.0,
    "adam_lr": 0.007
  }
}